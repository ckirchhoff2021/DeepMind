##  分布式训练原理

+ 随着模型尺寸和训练数据的大幅增加，只用一个GPU跑模型，速度会极慢，分布式训练在多个机器上一起训练模型，能极大的提高训练效率。

+ 分布式训练有两种思路：

  + 一是**模型并行**，将一个模型分拆成多个小模型，分别放在不同的设备上，每个设备只跑模型的一部分。由于模型的各个部分计算存在前后依赖，需要频繁通信，同步比较耗时，因此效率很低。

  + 二是**数据并行**，完整的模型在每个机器上都有，把数据分成多份给到每个模型，

